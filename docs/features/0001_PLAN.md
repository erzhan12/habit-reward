# Feature Plan: Gamified Habit-Reward System

## Overview
Build a scalable, gamified habit-reward system using Python (FastAPI), Airtable, Telegram Bot, and OpenAI for NLP. The system tracks habits with per-habit streaks, uses variable ratio rewards with streak multipliers, supports cumulative rewards with lifecycle status tracking (ðŸ•’ Pending, â³ Achieved, âœ… Completed), and provides a Streamlit dashboard for visualization.

Single-user initially (identified by Telegram ID), but designed for multi-user scalability.

---

## Phase 1: Data Layer

### Airtable Schema & Models

#### Tables Required
1. **Users**
   - Fields: `telegram_id` (unique), `name`, `active` (bool)

2. **Habits**
   - Fields: `name`, `weight` (float), `category`, `active` (bool)

3. **Rewards**
   - Fields: `name`, `weight` (float), `type` (enum: virtual/real/none/cumulative), `is_cumulative` (bool), `pieces_required` (int), `piece_value` (float)

4. **Reward Progress**
   - Fields: `user_id` (link to Users), `reward_id` (link to Rewards), `pieces_earned` (int), `status` (enum: ðŸ•’ Pending/â³ Achieved/âœ… Completed), `progress_percent` (formula), `status_emoji` (formula)

5. **Habit Log**
   - Fields: `user_id` (link to Users), `habit_id` (link to Habits), `timestamp`, `reward_id` (link to Rewards), `got_reward` (bool), `streak_count` (int), `habit_weight` (float), `total_weight_applied` (float), `last_completed_date` (date)

#### Files to Create
- `src/models/user.py` - Pydantic model for User with telegram_id, name, active
- `src/models/habit.py` - Pydantic model for Habit with name, weight, category, active
- `src/models/reward.py` - Pydantic model for Reward with all fields including cumulative logic
- `src/models/reward_progress.py` - Pydantic model for RewardProgress with status tracking
- `src/models/habit_log.py` - Pydantic model for HabitLog with streak and weight data
- `src/airtable/client.py` - Airtable API client wrapper using pyairtable
- `src/airtable/repositories.py` - Repository pattern for each table (UserRepository, HabitRepository, etc.)

### Configuration
- `src/config.py` - Environment variables (AIRTABLE_API_KEY, AIRTABLE_BASE_ID, TELEGRAM_BOT_TOKEN, OPENAI_API_KEY)
- `.env.example` - Template for environment variables
- `requirements.txt` - Dependencies (fastapi, uvicorn, python-telegram-bot, pyairtable, openai, pydantic, streamlit)

---

## Phase 2A: Core Habit Logic

### Streak Calculation Algorithm
**Per-habit streak tracking:**
1. Query Habit Log for the specific habit_id and user_id
2. Get the most recent log entry for that habit
3. Extract `last_completed_date` from that entry
4. If `last_completed_date` is yesterday: increment streak
5. If `last_completed_date` is today: return current streak (already logged today)
6. Otherwise: reset streak to 1
7. Store new streak_count in the new log entry

#### Files to Create
- `src/services/streak_service.py`
  - `calculate_streak(user_id: str, habit_id: str) -> int` - Implements algorithm above
  - `get_last_completed_date(user_id: str, habit_id: str) -> datetime | None`

### Reward Weight Calculation Algorithm
**Total reward multiplier formula:**
```
total_weight = habit_weight Ã— streak_multiplier
where streak_multiplier = 1 + (streak_count Ã— 0.1)
```

#### Weighted Random Reward Selection Algorithm
1. Fetch all active rewards from Rewards table
2. Include rewards with `type = "none"` to simulate no reward
3. Include cumulative rewards (`is_cumulative = true`)
4. Calculate adjusted weights for each reward using total_weight multiplier
5. Perform weighted random selection using `random.choices()` with weights
6. Return selected reward

#### Files to Create
- `src/services/reward_service.py`
  - `calculate_total_weight(habit_weight: float, streak_count: int) -> float`
  - `select_reward(total_weight: float) -> Reward` - Implements weighted random selection
  - `update_cumulative_progress(user_id: str, reward_id: str) -> RewardProgress | None` - Increment pieces, check if pieces >= pieces_required, update status to â³ Achieved if met
  - `get_active_rewards() -> list[Reward]`

### Habit Completion Flow
**Main orchestration for `/habit_done` command:**
1. Verify user exists in Users table by telegram_id
2. Get habit (from selection or NLP classification)
3. Pull habit weight from Habits table
4. Pull user weight from Users table
5. Calculate current streak for this specific habit
6. Calculate total_weight multiplier
7. Fetch all active rewards
8. Run weighted random draw
9. If cumulative reward: update Reward Progress, check if achieved
10. Log entry to Habit Log with all calculated values
11. Return response object with habit confirmation, reward result, streak status, cumulative progress

#### Files to Create
- `src/services/habit_service.py`
  - `process_habit_completion(user_telegram_id: str, habit_name: str) -> HabitCompletionResult` - Main orchestration function implementing flow above
  - `get_habit_by_name(habit_name: str) -> Habit`
  - `log_habit_completion(user_id: str, habit_id: str, reward_id: str, streak_count: int, habit_weight: float, total_weight: float) -> HabitLog`

- `src/models/habit_completion_result.py` - Response model containing:
  - `habit_confirmed: bool`
  - `reward: Reward | None`
  - `streak_count: int`
  - `cumulative_progress: RewardProgress | None`
  - `motivational_quote: str | None`

---

## Phase 2B: Telegram Bot Integration

### Bot Commands
- `/habit_done` - Trigger habit completion flow
- `/add_reward` - Add new reward via conversational input
- `/list_rewards` - List all active rewards
- `/my_rewards` - Show cumulative reward progress (all statuses)
- `/claim_reward <reward_name>` - Mark reward status as âœ… Completed
- `/set_reward_status <reward_name> <status>` - Manually update reward status
- `/streaks` - Show current streaks per habit

### Habit Selection Flow for `/habit_done`
1. Send inline keyboard with list of active habits
2. User can select from keyboard OR type custom text
3. If custom text: pass to OpenAI for classification (Phase 2C)
4. Once habit identified: call `process_habit_completion()`
5. Format and send response message with:
   - âœ… Habit confirmation
   - ðŸŽ Reward result (or âŒ No reward this time)
   - ðŸ”¥ Streak status
   - â³ Cumulative reward progress (if applicable)
   - ðŸ§  Motivational quote (optional)

### Files to Create
- `src/bot/main.py` - Initialize bot with python-telegram-bot, register handlers
- `src/bot/handlers/habit_done_handler.py` - ConversationHandler for /habit_done flow
  - State: AWAITING_HABIT_SELECTION
  - Callbacks for inline keyboard and text input
- `src/bot/handlers/reward_handlers.py` - Handlers for /add_reward, /list_rewards, /my_rewards, /claim_reward, /set_reward_status
- `src/bot/handlers/streak_handler.py` - Handler for /streaks command
- `src/bot/keyboards.py` - InlineKeyboardMarkup builders for habit selection
- `src/bot/formatters.py` - Message formatting functions for responses

---

## Phase 2C: OpenAI NLP Integration

### Habit Classification from Custom Text
**Algorithm:**
1. Fetch all active habit names from Habits table
2. Construct prompt:
   ```
   You are an AI that maps user habit logs to known habits.
   Available habits:
   - Walking
   - Journaling
   - Meditation
   - Coding
   - Reading

   User input: "{user_text}"
   Match to one or more habits from the list above. Return as JSON array.
   ```
3. Call OpenAI API (gpt-4 or gpt-3.5-turbo)
4. Parse JSON response to extract matched habit(s)
5. If multiple habits matched: process each sequentially
6. If no match: ask user to select manually

### Files to Create
- `src/services/nlp_service.py`
  - `classify_habit_from_text(user_text: str, available_habits: list[str]) -> list[str]` - Implements algorithm above
  - `build_classification_prompt(user_text: str, habits: list[str]) -> str`

---

## Phase 3: Streamlit Dashboard

### Dashboard Features
1. **Habit Logs View** - Table showing recent habit completions with streaks
2. **Cumulative Reward Progress** - Cards showing each reward with:
   - Progress bar (pieces_earned / pieces_required)
   - Status emoji (ðŸ•’/â³/âœ…)
   - Progress percentage
3. **Actionable Rewards Section** - Filtered view of â³ Achieved rewards with "Mark Completed" buttons
4. **Reward Value Overview** - Summary cards:
   - Total value earned
   - Total value claimed
   - Pending value
5. **Per-Habit Streak Chart** - Bar chart showing current streak for each habit

### Files to Create
- `src/dashboard/app.py` - Main Streamlit app
- `src/dashboard/components/habit_logs.py` - Habit logs table component
- `src/dashboard/components/reward_progress.py` - Reward progress cards
- `src/dashboard/components/actionable_rewards.py` - Achieved rewards with action buttons
- `src/dashboard/components/stats_overview.py` - Summary statistics
- `src/dashboard/components/streak_chart.py` - Streak visualization

---

## API Structure (Optional - for future expansion)

If building with FastAPI for future web integration:

### Files to Create
- `src/api/main.py` - FastAPI app initialization
- `src/api/routes/habits.py` - REST endpoints for habits
- `src/api/routes/rewards.py` - REST endpoints for rewards
- `src/api/routes/users.py` - REST endpoints for users
- `src/api/routes/progress.py` - REST endpoints for reward progress

---

## Project Structure Summary

```
habit_reward/
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ habit.py
â”‚   â”‚   â”œâ”€â”€ reward.py
â”‚   â”‚   â”œâ”€â”€ reward_progress.py
â”‚   â”‚   â”œâ”€â”€ habit_log.py
â”‚   â”‚   â””â”€â”€ habit_completion_result.py
â”‚   â”œâ”€â”€ airtable/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â””â”€â”€ repositories.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ streak_service.py
â”‚   â”‚   â”œâ”€â”€ reward_service.py
â”‚   â”‚   â”œâ”€â”€ habit_service.py
â”‚   â”‚   â””â”€â”€ nlp_service.py
â”‚   â”œâ”€â”€ bot/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ keyboards.py
â”‚   â”‚   â”œâ”€â”€ formatters.py
â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ habit_done_handler.py
â”‚   â”‚       â”œâ”€â”€ reward_handlers.py
â”‚   â”‚       â””â”€â”€ streak_handler.py
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ habit_logs.py
â”‚   â”‚       â”œâ”€â”€ reward_progress.py
â”‚   â”‚       â”œâ”€â”€ actionable_rewards.py
â”‚   â”‚       â”œâ”€â”€ stats_overview.py
â”‚   â”‚       â””â”€â”€ streak_chart.py
â”‚   â””â”€â”€ api/ (optional)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ routes/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ habits.py
â”‚           â”œâ”€â”€ rewards.py
â”‚           â”œâ”€â”€ users.py
â”‚           â””â”€â”€ progress.py
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_streak_service.py
    â”œâ”€â”€ test_reward_service.py
    â””â”€â”€ test_habit_service.py
```

---

## Key Algorithms Detail

### 1. Per-Habit Streak Calculation
```
INPUT: user_id, habit_id
OUTPUT: current_streak

1. last_log = query_habit_log(user_id, habit_id, order_by='timestamp DESC', limit=1)
2. IF last_log is None:
     RETURN 1  # First time completing this habit
3. last_date = last_log.last_completed_date
4. today = current_date()
5. IF last_date == today:
     RETURN last_log.streak_count  # Already logged today
6. IF last_date == today - 1 day:
     RETURN last_log.streak_count + 1  # Consecutive day
7. ELSE:
     RETURN 1  # Streak broken, reset
```

### 2. Weighted Random Reward Selection
```
INPUT: total_weight (float)
OUTPUT: selected_reward (Reward)

1. rewards = get_all_active_rewards()  # Includes type="none" and cumulative
2. adjusted_weights = []
3. FOR each reward in rewards:
     adjusted_weight = reward.weight * total_weight
     adjusted_weights.append(adjusted_weight)
4. selected_reward = random.choices(rewards, weights=adjusted_weights, k=1)[0]
5. RETURN selected_reward
```

### 3. Cumulative Reward Progress Update
```
INPUT: user_id, reward_id
OUTPUT: reward_progress (RewardProgress)

1. progress = get_reward_progress(user_id, reward_id)
2. IF progress is None:
     progress = create_reward_progress(user_id, reward_id, pieces_earned=0, status="ðŸ•’ Pending")
3. progress.pieces_earned += 1
4. reward = get_reward(reward_id)
5. IF progress.pieces_earned >= reward.pieces_required:
     progress.status = "â³ Achieved"
     progress.actionable_now = True
6. ELSE:
     progress.status = "ðŸ•’ Pending"
     progress.actionable_now = False
7. progress.progress_percent = (progress.pieces_earned / reward.pieces_required) * 100
8. update_reward_progress(progress)
9. RETURN progress
```

---

## Dependencies

```
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
python-telegram-bot>=20.6
pyairtable>=2.2.0
openai>=1.3.0
pydantic>=2.5.0
pydantic-settings>=2.1.0
streamlit>=1.28.0
python-dotenv>=1.0.0
```

---

## Ethical Considerations Implementation

1. **Data Privacy**
   - Store only telegram_id, no personal data beyond user-provided name
   - All data in Airtable (user has full control and export capability)
   - No tracking beyond habit logging

2. **Transparent Reward Logic**
   - All weight calculations logged in Habit Log
   - Users can see exact formula in dashboard
   - No hidden manipulation of probabilities

3. **Motivation vs Addiction**
   - Use streak_multiplier capped at reasonable levels
   - Reward "none" type always included to avoid guaranteed rewards
   - Dashboard emphasizes progress, not just rewards

4. **Extensibility**
   - Use repository pattern for easy database swap (Airtable â†’ SQLite/Postgres)
   - Modular service layer separates business logic from data access
   - Configuration-driven design for easy customization
